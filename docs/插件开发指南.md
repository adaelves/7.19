# 插件开发指南

## 目录
1. [插件系统概述](#插件系统概述)
2. [开发环境准备](#开发环境准备)
3. [插件基础结构](#插件基础结构)
4. [API参考](#api参考)
5. [开发示例](#开发示例)
6. [测试和调试](#测试和调试)
7. [发布和分发](#发布和分发)
8. [最佳实践](#最佳实践)

## 插件系统概述

多平台视频下载器采用插件化架构，允许开发者为新的视频平台创建提取器插件。插件系统具有以下特性：

### 核心特性
- **动态加载**: 运行时加载和卸载插件
- **安全隔离**: 插件在受限环境中运行
- **统一接口**: 所有插件遵循相同的API规范
- **热更新**: 无需重启即可更新插件
- **错误隔离**: 单个插件错误不影响整体系统

### 插件类型
- **视频提取器**: 从视频网站提取下载链接
- **元数据提取器**: 提取视频标题、作者等信息
- **认证处理器**: 处理登录和Cookie认证
- **后处理器**: 下载后的文件处理

## 开发环境准备

### 系统要求
- Python 3.8+
- 基本的网络编程知识
- 了解HTTP协议和网页解析

### 开发工具
```bash
# 安装开发依赖
pip install requests beautifulsoup4 lxml selenium

# 可选工具
pip install pytest black flake8  # 测试和代码格式化
```

### 项目结构
```
plugins/
├── __init__.py
├── base.py                 # 基类定义
├── youtube.py             # YouTube插件示例
├── custom_site.py         # 你的自定义插件
└── tests/
    ├── test_custom_site.py
    └── fixtures/
```

## 插件基础结构

### BaseExtractor基类

所有插件必须继承自`BaseExtractor`基类：

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
import re

class BaseExtractor(ABC):
    """插件基类，所有提取器插件必须继承此类"""
    
    @property
    @abstractmethod
    def supported_domains(self) -> List[str]:
        """返回支持的域名列表"""
        pass
    
    @property
    @abstractmethod
    def plugin_name(self) -> str:
        """插件名称"""
        pass
    
    @property
    @abstractmethod
    def plugin_version(self) -> str:
        """插件版本"""
        pass
    
    @abstractmethod
    def can_handle(self, url: str) -> bool:
        """检查是否能处理给定的URL"""
        pass
    
    @abstractmethod
    def extract_info(self, url: str) -> Dict[str, Any]:
        """提取视频信息"""
        pass
    
    @abstractmethod
    def get_download_urls(self, info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """获取下载链接"""
        pass
    
    # 可选方法
    def extract_playlist(self, url: str) -> List[Dict[str, Any]]:
        """提取播放列表 (可选实现)"""
        return []
    
    def authenticate(self, credentials: Dict[str, str]) -> bool:
        """认证处理 (可选实现)"""
        return True
    
    def get_user_videos(self, user_url: str) -> List[Dict[str, Any]]:
        """获取用户所有视频 (可选实现)"""
        return []
```

### 基本插件模板

```python
import re
import requests
from bs4 import BeautifulSoup
from typing import Dict, List, Any
from .base import BaseExtractor

class CustomSiteExtractor(BaseExtractor):
    """自定义网站提取器示例"""
    
    @property
    def supported_domains(self) -> List[str]:
        return ["example.com", "www.example.com"]
    
    @property
    def plugin_name(self) -> str:
        return "CustomSite"
    
    @property
    def plugin_version(self) -> str:
        return "1.0.0"
    
    def can_handle(self, url: str) -> bool:
        """检查URL是否属于支持的域名"""
        for domain in self.supported_domains:
            if domain in url:
                return True
        return False
    
    def extract_info(self, url: str) -> Dict[str, Any]:
        """提取视频基本信息"""
        try:
            response = requests.get(url, headers=self._get_headers())
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # 提取基本信息
            title = self._extract_title(soup)
            author = self._extract_author(soup)
            thumbnail = self._extract_thumbnail(soup)
            duration = self._extract_duration(soup)
            
            return {
                'id': self._extract_video_id(url),
                'title': title,
                'author': author,
                'thumbnail': thumbnail,
                'duration': duration,
                'url': url,
                'platform': self.plugin_name
            }
            
        except Exception as e:
            raise Exception(f"Failed to extract info: {str(e)}")
    
    def get_download_urls(self, info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """获取实际下载链接"""
        try:
            video_id = info['id']
            api_url = f"https://api.example.com/video/{video_id}"
            
            response = requests.get(api_url, headers=self._get_headers())
            data = response.json()
            
            download_urls = []
            for quality in data.get('qualities', []):
                download_urls.append({
                    'url': quality['url'],
                    'quality': quality['height'],
                    'format': quality['format'],
                    'filesize': quality.get('filesize', 0)
                })
            
            return download_urls
            
        except Exception as e:
            raise Exception(f"Failed to get download URLs: {str(e)}")
    
    def _get_headers(self) -> Dict[str, str]:
        """获取请求头"""
        return {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
    
    def _extract_title(self, soup: BeautifulSoup) -> str:
        """提取视频标题"""
        title_elem = soup.find('h1', class_='video-title')
        return title_elem.text.strip() if title_elem else "Unknown Title"
    
    def _extract_author(self, soup: BeautifulSoup) -> str:
        """提取作者名称"""
        author_elem = soup.find('span', class_='author-name')
        return author_elem.text.strip() if author_elem else "Unknown Author"
    
    def _extract_thumbnail(self, soup: BeautifulSoup) -> str:
        """提取缩略图URL"""
        thumb_elem = soup.find('meta', property='og:image')
        return thumb_elem.get('content', '') if thumb_elem else ''
    
    def _extract_duration(self, soup: BeautifulSoup) -> int:
        """提取视频时长 (秒)"""
        duration_elem = soup.find('meta', itemprop='duration')
        if duration_elem:
            # 解析ISO 8601格式 (PT1M30S -> 90秒)
            duration_str = duration_elem.get('content', '')
            return self._parse_duration(duration_str)
        return 0
    
    def _extract_video_id(self, url: str) -> str:
        """从URL提取视频ID"""
        match = re.search(r'/video/(\w+)', url)
        return match.group(1) if match else ''
    
    def _parse_duration(self, duration_str: str) -> int:
        """解析时长字符串为秒数"""
        # 实现时长解析逻辑
        # 例如: "PT1M30S" -> 90
        pass

# 插件注册 (必需)
def get_extractor():
    """插件入口函数"""
    return CustomSiteExtractor()
```

## API参考

### 核心方法详解

#### extract_info()
提取视频基本信息，返回标准化的字典格式：

```python
{
    'id': str,              # 视频唯一标识
    'title': str,           # 视频标题
    'author': str,          # 作者/上传者
    'thumbnail': str,       # 缩略图URL
    'duration': int,        # 时长(秒)
    'view_count': int,      # 播放量 (可选)
    'upload_date': str,     # 上传日期 (YYYY-MM-DD)
    'description': str,     # 视频描述 (可选)
    'tags': List[str],      # 标签列表 (可选)
    'url': str,             # 原始URL
    'platform': str         # 平台名称
}
```

#### get_download_urls()
返回可用的下载链接列表：

```python
[
    {
        'url': str,         # 下载链接
        'quality': str,     # 质量标识 (720p, 1080p等)
        'format': str,      # 文件格式 (mp4, webm等)
        'filesize': int,    # 文件大小 (字节)
        'codec': str,       # 编码格式 (可选)
        'fps': int,         # 帧率 (可选)
        'audio_only': bool  # 是否仅音频 (可选)
    }
]
```

### 工具函数

插件可以使用以下工具函数：

```python
from app.core.utils import (
    sanitize_filename,      # 清理文件名
    parse_duration,         # 解析时长
    format_filesize,        # 格式化文件大小
    extract_domain,         # 提取域名
    is_valid_url,          # 验证URL
    retry_on_failure,      # 重试装饰器
    rate_limit            # 限流装饰器
)

# 使用示例
@retry_on_failure(max_retries=3)
@rate_limit(calls=10, period=60)  # 每分钟最多10次调用
def fetch_video_info(self, url: str):
    # 网络请求逻辑
    pass
```

### 错误处理

插件应该正确处理各种异常情况：

```python
from app.core.exceptions import (
    ExtractionError,        # 提取失败
    AuthenticationError,    # 认证失败
    GeoblockError,         # 地域限制
    PrivateVideoError,     # 私有视频
    VideoUnavailableError  # 视频不可用
)

def extract_info(self, url: str) -> Dict[str, Any]:
    try:
        # 提取逻辑
        pass
    except requests.HTTPError as e:
        if e.response.status_code == 403:
            raise GeoblockError("Video blocked in your region")
        elif e.response.status_code == 404:
            raise VideoUnavailableError("Video not found")
        else:
            raise ExtractionError(f"HTTP error: {e}")
    except Exception as e:
        raise ExtractionError(f"Extraction failed: {e}")
```

## 开发示例

### 简单视频网站插件

```python
class SimpleVideoExtractor(BaseExtractor):
    """简单视频网站插件示例"""
    
    @property
    def supported_domains(self) -> List[str]:
        return ["simplevideo.com"]
    
    @property
    def plugin_name(self) -> str:
        return "SimpleVideo"
    
    @property
    def plugin_version(self) -> str:
        return "1.0.0"
    
    def can_handle(self, url: str) -> bool:
        return "simplevideo.com" in url
    
    def extract_info(self, url: str) -> Dict[str, Any]:
        # 发送HTTP请求
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 提取JSON数据
        script_tag = soup.find('script', type='application/ld+json')
        if script_tag:
            data = json.loads(script_tag.string)
            return {
                'id': self._extract_id_from_url(url),
                'title': data.get('name', ''),
                'author': data.get('author', {}).get('name', ''),
                'thumbnail': data.get('thumbnailUrl', ''),
                'duration': self._parse_duration(data.get('duration', '')),
                'url': url,
                'platform': self.plugin_name
            }
        
        raise ExtractionError("Could not find video data")
    
    def get_download_urls(self, info: Dict[str, Any]) -> List[Dict[str, Any]]:
        # 构造API请求
        api_url = f"https://api.simplevideo.com/video/{info['id']}/streams"
        response = requests.get(api_url)
        data = response.json()
        
        urls = []
        for stream in data.get('streams', []):
            urls.append({
                'url': stream['url'],
                'quality': f"{stream['height']}p",
                'format': stream['format'],
                'filesize': stream.get('size', 0)
            })
        
        return urls
```

### 需要认证的网站插件

```python
class AuthRequiredExtractor(BaseExtractor):
    """需要认证的网站插件"""
    
    def __init__(self):
        super().__init__()
        self.session = requests.Session()
        self.authenticated = False
    
    def authenticate(self, credentials: Dict[str, str]) -> bool:
        """使用Cookie进行认证"""
        try:
            cookies = credentials.get('cookies', {})
            self.session.cookies.update(cookies)
            
            # 验证认证状态
            test_url = "https://example.com/api/user"
            response = self.session.get(test_url)
            
            if response.status_code == 200:
                self.authenticated = True
                return True
            else:
                return False
                
        except Exception as e:
            print(f"Authentication failed: {e}")
            return False
    
    def extract_info(self, url: str) -> Dict[str, Any]:
        if not self.authenticated:
            raise AuthenticationError("Authentication required")
        
        # 使用已认证的session进行请求
        response = self.session.get(url)
        # ... 提取逻辑
```

### 支持播放列表的插件

```python
class PlaylistExtractor(BaseExtractor):
    """支持播放列表的插件"""
    
    def extract_playlist(self, url: str) -> List[Dict[str, Any]]:
        """提取播放列表中的所有视频"""
        if not self._is_playlist_url(url):
            return []
        
        playlist_id = self._extract_playlist_id(url)
        api_url = f"https://api.example.com/playlist/{playlist_id}"
        
        response = requests.get(api_url)
        data = response.json()
        
        videos = []
        for item in data.get('items', []):
            video_info = {
                'id': item['id'],
                'title': item['title'],
                'author': item['author'],
                'url': f"https://example.com/video/{item['id']}",
                'thumbnail': item['thumbnail'],
                'duration': item['duration']
            }
            videos.append(video_info)
        
        return videos
    
    def _is_playlist_url(self, url: str) -> bool:
        return '/playlist/' in url
    
    def _extract_playlist_id(self, url: str) -> str:
        match = re.search(r'/playlist/(\w+)', url)
        return match.group(1) if match else ''
```

## 测试和调试

### 单元测试

为插件编写测试用例：

```python
import unittest
from unittest.mock import patch, Mock
from plugins.custom_site import CustomSiteExtractor

class TestCustomSiteExtractor(unittest.TestCase):
    
    def setUp(self):
        self.extractor = CustomSiteExtractor()
    
    def test_can_handle(self):
        """测试URL识别"""
        self.assertTrue(self.extractor.can_handle("https://example.com/video/123"))
        self.assertFalse(self.extractor.can_handle("https://other.com/video/123"))
    
    @patch('requests.get')
    def test_extract_info(self, mock_get):
        """测试信息提取"""
        # 模拟HTTP响应
        mock_response = Mock()
        mock_response.text = """
        <html>
            <h1 class="video-title">Test Video</h1>
            <span class="author-name">Test Author</span>
        </html>
        """
        mock_get.return_value = mock_response
        
        info = self.extractor.extract_info("https://example.com/video/123")
        
        self.assertEqual(info['title'], 'Test Video')
        self.assertEqual(info['author'], 'Test Author')
    
    def test_extract_video_id(self):
        """测试视频ID提取"""
        url = "https://example.com/video/abc123"
        video_id = self.extractor._extract_video_id(url)
        self.assertEqual(video_id, 'abc123')

if __name__ == '__main__':
    unittest.main()
```

### 调试技巧

1. **使用日志记录**
```python
import logging

logger = logging.getLogger(__name__)

def extract_info(self, url: str) -> Dict[str, Any]:
    logger.debug(f"Extracting info from: {url}")
    try:
        # 提取逻辑
        logger.info(f"Successfully extracted: {title}")
    except Exception as e:
        logger.error(f"Extraction failed: {e}")
        raise
```

2. **网络请求调试**
```python
import requests

# 启用详细日志
import http.client as http_client
http_client.HTTPConnection.debuglevel = 1

# 或使用requests-toolbelt
from requests_toolbelt.utils import dump
response = requests.get(url)
print(dump.dump_all(response).decode('utf-8'))
```

3. **浏览器开发者工具**
- 使用Network面板分析网络请求
- 查看XHR/Fetch请求获取API端点
- 分析页面结构和JavaScript代码

## 发布和分发

### 插件打包

创建插件包结构：
```
my_plugin/
├── __init__.py
├── extractor.py
├── README.md
├── requirements.txt
└── tests/
    └── test_extractor.py
```

### 插件元数据

在插件中包含完整的元数据：

```python
class MyExtractor(BaseExtractor):
    # 插件信息
    PLUGIN_INFO = {
        'name': 'MyExtractor',
        'version': '1.0.0',
        'author': 'Your Name',
        'description': 'Extractor for MyVideoSite',
        'homepage': 'https://github.com/yourname/my-extractor',
        'license': 'MIT',
        'supported_sites': ['myvideosite.com'],
        'requirements': ['requests>=2.25.0', 'beautifulsoup4>=4.9.0']
    }
```

### 发布检查清单

- [ ] 代码通过所有测试
- [ ] 遵循代码规范 (PEP 8)
- [ ] 包含完整的文档
- [ ] 处理所有异常情况
- [ ] 支持常见的视频格式和质量
- [ ] 测试在不同网络环境下的表现
- [ ] 验证插件安全性

## 最佳实践

### 性能优化

1. **缓存机制**
```python
from functools import lru_cache

class MyExtractor(BaseExtractor):
    
    @lru_cache(maxsize=100)
    def _get_video_info(self, video_id: str):
        """缓存视频信息"""
        # 网络请求逻辑
        pass
```

2. **异步请求**
```python
import asyncio
import aiohttp

async def fetch_multiple_videos(self, urls: List[str]):
    """并发获取多个视频信息"""
    async with aiohttp.ClientSession() as session:
        tasks = [self._fetch_video_info(session, url) for url in urls]
        return await asyncio.gather(*tasks)
```

3. **请求限流**
```python
import time
from functools import wraps

def rate_limit(calls_per_second=1):
    def decorator(func):
        last_called = [0.0]
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            left_to_wait = 1.0 / calls_per_second - elapsed
            if left_to_wait > 0:
                time.sleep(left_to_wait)
            ret = func(*args, **kwargs)
            last_called[0] = time.time()
            return ret
        return wrapper
    return decorator
```

### 错误处理

1. **优雅降级**
```python
def get_download_urls(self, info: Dict[str, Any]) -> List[Dict[str, Any]]:
    try:
        # 尝试获取高质量链接
        return self._get_hd_urls(info)
    except Exception:
        try:
            # 降级到标准质量
            return self._get_sd_urls(info)
        except Exception:
            # 最后尝试基础质量
            return self._get_basic_urls(info)
```

2. **重试机制**
```python
import time
import random

def retry_with_backoff(max_retries=3, base_delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    time.sleep(delay)
        return wrapper
    return decorator
```

### 安全考虑

1. **输入验证**
```python
def extract_info(self, url: str) -> Dict[str, Any]:
    # 验证URL格式
    if not self._is_valid_url(url):
        raise ValueError("Invalid URL format")
    
    # 检查域名白名单
    if not self._is_allowed_domain(url):
        raise SecurityError("Domain not allowed")
```

2. **防止代码注入**
```python
import html
import re

def sanitize_text(self, text: str) -> str:
    """清理用户输入的文本"""
    # HTML转义
    text = html.escape(text)
    # 移除危险字符
    text = re.sub(r'[<>"\']', '', text)
    return text.strip()
```

### 代码规范

1. **遵循PEP 8**
```python
# 使用black格式化代码
pip install black
black your_plugin.py

# 使用flake8检查代码质量
pip install flake8
flake8 your_plugin.py
```

2. **类型注解**
```python
from typing import Dict, List, Any, Optional

def extract_info(self, url: str) -> Dict[str, Any]:
    """提取视频信息
    
    Args:
        url: 视频URL
        
    Returns:
        包含视频信息的字典
        
    Raises:
        ExtractionError: 提取失败时抛出
    """
    pass
```

3. **文档字符串**
```python
class MyExtractor(BaseExtractor):
    """MyVideoSite视频提取器
    
    支持从MyVideoSite网站提取视频信息和下载链接。
    
    Attributes:
        supported_domains: 支持的域名列表
        plugin_name: 插件名称
        plugin_version: 插件版本
    
    Example:
        extractor = MyExtractor()
        if extractor.can_handle(url):
            info = extractor.extract_info(url)
            urls = extractor.get_download_urls(info)
    """
```

---

通过遵循本指南，您可以开发出高质量、稳定可靠的视频提取器插件。如有问题，欢迎在GitHub Issues中讨论交流！